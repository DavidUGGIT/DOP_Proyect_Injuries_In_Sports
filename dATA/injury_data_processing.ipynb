{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÄ‚öΩ Injury Data Processing - Injury Project\n",
    "\n",
    "## Project Goal\n",
    "Preparing and consolidating data from various sources on athlete injuries:\n",
    "- **NBA** - professional male basketball players (ACL)\n",
    "- **WNBA** - professional female basketball players (ACL)\n",
    "- **Soccer** - professional soccer players (various injuries)\n",
    "- **Collegiate** - student-athletes (injury risk)\n",
    "\n",
    "## Notebook Structure\n",
    "1. Library imports and data loading\n",
    "2. Exploration and cleaning of each dataset\n",
    "3. Transformation and standardization\n",
    "4. Consolidation into one Excel file\n",
    "5. Summary and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Library Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display configuration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")\n",
    "print(f\"üìÖ Processing date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Loading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "EXCEL_FILE = '/mnt/user-data/uploads/Excel-licencjat.xlsx'\n",
    "COLLEGIATE_FILE = 'collegiate_athlete_injury_dataset.csv'\n",
    "SOCCER_FILE = 'player_injuries_impact.csv'\n",
    "\n",
    "# Load NBA\n",
    "print(\"üì• Loading NBA data...\")\n",
    "df_nba_raw = pd.read_excel(EXCEL_FILE, sheet_name='Basketball-man')\n",
    "print(f\"   NBA: {df_nba_raw.shape[0]} rows √ó {df_nba_raw.shape[1]} columns\")\n",
    "\n",
    "# Load WNBA\n",
    "print(\"üì• Loading WNBA data...\")\n",
    "df_wnba_raw = pd.read_excel(EXCEL_FILE, sheet_name='Basketball-woman')\n",
    "print(f\"   WNBA: {df_wnba_raw.shape[0]} rows √ó {df_wnba_raw.shape[1]} columns\")\n",
    "\n",
    "# Load Soccer\n",
    "print(\"üì• Loading Soccer data...\")\n",
    "df_soccer_raw = pd.read_csv(SOCCER_FILE)\n",
    "print(f\"   Soccer: {df_soccer_raw.shape[0]} rows √ó {df_soccer_raw.shape[1]} columns\")\n",
    "\n",
    "# Load Collegiate\n",
    "print(\"üì• Loading Collegiate data...\")\n",
    "df_collegiate_raw = pd.read_csv(COLLEGIATE_FILE)\n",
    "print(f\"   Collegiate: {df_collegiate_raw.shape[0]} rows √ó {df_collegiate_raw.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n‚úÖ All data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. NBA Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç NBA DATA EXPLORATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Basic info\n",
    "print(\"\\nüìä Columns:\")\n",
    "print(df_nba_raw.columns.tolist())\n",
    "\n",
    "print(\"\\nüìä First 5 rows:\")\n",
    "display(df_nba_raw.head())\n",
    "\n",
    "print(\"\\nüìä Data types:\")\n",
    "print(df_nba_raw.dtypes)\n",
    "\n",
    "print(\"\\nüìä Missing values:\")\n",
    "missing = df_nba_raw.isnull().sum()\n",
    "print(missing[missing > 0].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nüìä Unique values in 'Name - Season':\")\n",
    "print(f\"   Total: {df_nba_raw['Name - Season'].nunique()}\")\n",
    "print(\"\\n   Examples:\")\n",
    "for name in df_nba_raw['Name - Season'].head(15):\n",
    "    print(f\"   ‚Ä¢ {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. NBA Data Structure Analysis\n",
    "\n",
    "The NBA data has a specific structure:\n",
    "- Each player has multiple rows: season before injury, seasons after, `summary before`, `summary after`\n",
    "- Stat columns are in \"made-attempted\" format (e.g., \"5.2-12.3\")\n",
    "- Shooting percentages are in separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many players have summary before/after\n",
    "summary_before = df_nba_raw[df_nba_raw['Name - Season'].str.contains('summary before', na=False)]\n",
    "summary_after = df_nba_raw[df_nba_raw['Name - Season'].str.contains('summary after', na=False)]\n",
    "\n",
    "print(f\"üìä Players with 'summary before': {len(summary_before)}\")\n",
    "print(f\"üìä Players with 'summary after': {len(summary_after)}\")\n",
    "\n",
    "# Extract player names\n",
    "players_nba = summary_before['Name - Season'].str.replace(' summary before', '').tolist()\n",
    "print(f\"\\nüìä Unique NBA players: {len(players_nba)}\")\n",
    "print(\"\\n   Player list:\")\n",
    "for i, player in enumerate(players_nba, 1):\n",
    "    print(f\"   {i:2d}. {player}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. WNBA Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç WNBA DATA EXPLORATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Columns:\")\n",
    "print(df_wnba_raw.columns.tolist())\n",
    "\n",
    "print(\"\\nüìä First 5 rows:\")\n",
    "display(df_wnba_raw.head())\n",
    "\n",
    "print(\"\\nüìä Missing values:\")\n",
    "missing = df_wnba_raw.isnull().sum()\n",
    "print(missing[missing > 0].sort_values(ascending=False))\n",
    "\n",
    "# WNBA players\n",
    "summary_before_wnba = df_wnba_raw[df_wnba_raw['Name - Season'].str.contains('summary before', na=False)]\n",
    "players_wnba = summary_before_wnba['Name - Season'].str.replace(' summary before', '').tolist()\n",
    "\n",
    "print(f\"\\nüìä Unique WNBA players: {len(players_wnba)}\")\n",
    "print(\"\\n   Player list:\")\n",
    "for i, player in enumerate(players_wnba, 1):\n",
    "    print(f\"   {i:2d}. {player}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Soccer Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç SOCCER DATA EXPLORATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Columns:\")\n",
    "print(df_soccer_raw.columns.tolist())\n",
    "\n",
    "print(\"\\nüìä First 3 rows:\")\n",
    "display(df_soccer_raw.head(3))\n",
    "\n",
    "print(\"\\nüìä Injury types:\")\n",
    "injury_counts = df_soccer_raw['Injury'].value_counts()\n",
    "print(f\"   Number of unique types: {df_soccer_raw['Injury'].nunique()}\")\n",
    "print(\"\\n   Top 20 most common injuries:\")\n",
    "print(injury_counts.head(20))\n",
    "\n",
    "print(\"\\nüìä Missing values:\")\n",
    "missing = df_soccer_raw.isnull().sum()\n",
    "print(missing[missing > 0].sort_values(ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Collegiate Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç COLLEGIATE DATA EXPLORATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Columns:\")\n",
    "print(df_collegiate_raw.columns.tolist())\n",
    "\n",
    "print(\"\\nüìä First 5 rows:\")\n",
    "display(df_collegiate_raw.head())\n",
    "\n",
    "print(\"\\nüìä Basic statistics:\")\n",
    "display(df_collegiate_raw.describe())\n",
    "\n",
    "print(\"\\nüìä Gender distribution:\")\n",
    "print(df_collegiate_raw['Gender'].value_counts())\n",
    "\n",
    "print(\"\\nüìä Position distribution:\")\n",
    "print(df_collegiate_raw['Position'].value_counts())\n",
    "\n",
    "print(\"\\nüìä Injury Indicator (0=no injury, 1=injury):\")\n",
    "print(df_collegiate_raw['Injury_Indicator'].value_counts())\n",
    "\n",
    "print(\"\\nüìä Missing values:\")\n",
    "print(df_collegiate_raw.isnull().sum().sum(), \"- NO missing values! ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Helper Functions for Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_made_attempted(value):\n",
    "    \"\"\"\n",
    "    Splits values like '5.2-12.3' into (made, attempted)\n",
    "    \n",
    "    Args:\n",
    "        value: String in 'made-attempted' format or a number\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (made, attempted) as floats or (NaN, NaN)\n",
    "    \"\"\"\n",
    "    if pd.isnull(value):\n",
    "        return (np.nan, np.nan)\n",
    "    \n",
    "    s = str(value).replace(',', '.')\n",
    "    \n",
    "    if '-' in s:\n",
    "        try:\n",
    "            parts = s.split('-')\n",
    "            made = float(parts[0].strip())\n",
    "            attempted = float(parts[1].strip())\n",
    "            return (round(made, 2), round(attempted, 2))\n",
    "        except:\n",
    "            return (np.nan, np.nan)\n",
    "    else:\n",
    "        try:\n",
    "            return (float(s), np.nan)\n",
    "        except:\n",
    "            return (np.nan, np.nan)\n",
    "\n",
    "# Test the function\n",
    "print(\"üß™ Test split_made_attempted:\")\n",
    "test_cases = ['5.2-12.3', '10-20', '15.5', None, 'abc']\n",
    "for tc in test_cases:\n",
    "    result = split_made_attempted(tc)\n",
    "    print(f\"   {tc} ‚Üí {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_injury(injury_name):\n",
    "    \"\"\"\n",
    "    Categorizes soccer injuries into main groups\n",
    "    \n",
    "    Args:\n",
    "        injury_name: Injury name\n",
    "    \n",
    "    Returns:\n",
    "        str: Injury category\n",
    "    \"\"\"\n",
    "    if pd.isnull(injury_name):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    injury_lower = str(injury_name).lower()\n",
    "    \n",
    "    # ACL and other cruciate ligaments\n",
    "    if 'cruciate' in injury_lower or 'acl' in injury_lower:\n",
    "        return 'Knee - Cruciate Ligament'\n",
    "    \n",
    "    # Knee in general\n",
    "    if 'knee' in injury_lower:\n",
    "        return 'Knee - Other'\n",
    "    \n",
    "    # Hamstring\n",
    "    if 'hamstring' in injury_lower:\n",
    "        return 'Muscle - Hamstring'\n",
    "    \n",
    "    if 'groin' in injury_lower:\n",
    "        return 'Muscle - Groin'\n",
    "    \n",
    "    if 'calf' in injury_lower:\n",
    "        return 'Muscle - Calf'\n",
    "    \n",
    "    # Muscle in general\n",
    "    if 'muscle' in injury_lower:\n",
    "        return 'Muscle - Other'\n",
    "    \n",
    "    # Ankle\n",
    "    if 'ankle' in injury_lower:\n",
    "        return 'Ankle'\n",
    "    \n",
    "    # Foot\n",
    "    if 'foot' in injury_lower:\n",
    "        return 'Foot'\n",
    "    \n",
    "    # Hip\n",
    "    if 'hip' in injury_lower:\n",
    "        return 'Hip'\n",
    "    \n",
    "    # Shoulder\n",
    "    if 'shoulder' in injury_lower:\n",
    "        return 'Shoulder'\n",
    "    \n",
    "    # Hand/finger\n",
    "    if 'hand' in injury_lower or 'finger' in injury_lower:\n",
    "        return 'Hand'\n",
    "    \n",
    "    # Illness/fatigue\n",
    "    if 'virus' in injury_lower or 'coronavirus' in injury_lower or 'covid' in injury_lower:\n",
    "        return 'Illness - Virus'\n",
    "    \n",
    "    if 'fatigue' in injury_lower:\n",
    "        return 'Fatigue'\n",
    "    \n",
    "    # Other\n",
    "    return 'Other'\n",
    "\n",
    "# Test the function\n",
    "print(\"üß™ Test categorize_injury:\")\n",
    "test_injuries = [\n",
    "    'Cruciate ligament tear',\n",
    "    'Knee injury',\n",
    "    'Hamstring strain',\n",
    "    'Groin problems',\n",
    "    'Ankle injury',\n",
    "    'Coronavirus',\n",
    "    'Muscle fatigue',\n",
    "    'Unknown injury'\n",
    "]\n",
    "for inj in test_injuries:\n",
    "    cat = categorize_injury(inj)\n",
    "    print(f\"   {inj:30s} ‚Üí {cat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. NBA Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚öôÔ∏è NBA DATA PROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Copy of raw data\n",
    "df_nba = df_nba_raw.copy()\n",
    "\n",
    "# 1. Add League column\n",
    "df_nba['League'] = 'NBA'\n",
    "\n",
    "# 2. Add Injury_Type column\n",
    "df_nba['Injury_Type'] = 'ACL'\n",
    "\n",
    "# 3. Standardize Gender column name\n",
    "if 'gender' in df_nba.columns:\n",
    "    df_nba.rename(columns={'gender': 'Gender'}, inplace=True)\n",
    "\n",
    "# 4. Split made-attempted columns\n",
    "print(\"\\nüìä Splitting Field Goals (FG), 3-Point (3PT), Free Throws (FT) columns...\")\n",
    "\n",
    "# Field Goals\n",
    "if 'Field goals made-attempted per game' in df_nba.columns:\n",
    "    fg_split = df_nba['Field goals made-attempted per game'].apply(split_made_attempted)\n",
    "    df_nba['FG_made'] = fg_split.apply(lambda x: x[0])\n",
    "    df_nba['FG_attempted'] = fg_split.apply(lambda x: x[1])\n",
    "    print(\"   ‚úÖ FG split into FG_made and FG_attempted\")\n",
    "\n",
    "# 3-Point\n",
    "if 'Three-point field goals made-attempted per game' in df_nba.columns:\n",
    "    tpt_split = df_nba['Three-point field goals made-attempted per game'].apply(split_made_attempted)\n",
    "    df_nba['3PT_made'] = tpt_split.apply(lambda x: x[0])\n",
    "    df_nba['3PT_attempted'] = tpt_split.apply(lambda x: x[1])\n",
    "    print(\"   ‚úÖ 3PT split into 3PT_made and 3PT_attempted\")\n",
    "\n",
    "# Free Throws\n",
    "if 'Free throws made-attempted per game' in df_nba.columns:\n",
    "    ft_split = df_nba['Free throws made-attempted per game'].apply(split_made_attempted)\n",
    "    df_nba['FT_made'] = ft_split.apply(lambda x: x[0])\n",
    "    df_nba['FT_attempted'] = ft_split.apply(lambda x: x[1])\n",
    "    print(\"   ‚úÖ FT split into FT_made and FT_attempted\")\n",
    "\n",
    "# 5. Calculate GS_percent (games started percentage)\n",
    "df_nba['GS_percent'] = np.nan\n",
    "mask = (df_nba['games played'].notna()) & (df_nba['games played'] > 0)\n",
    "df_nba.loc[mask, 'GS_percent'] = (df_nba.loc[mask, 'GS'] / df_nba.loc[mask, 'games played'] * 100).round(2)\n",
    "    print(\"   ‚úÖ Added GS_percent (% of games started)\")\n",
    "\n",
    "# 6. Extract period info (before/after/season)\n",
    "def get_period(name_season):\n",
    "    if pd.isnull(name_season):\n",
    "        return np.nan\n",
    "    name_str = str(name_season)\n",
    "    if 'summary before' in name_str:\n",
    "        return 'Summary Before'\n",
    "    elif 'summary after' in name_str:\n",
    "        return 'Summary After'\n",
    "    else:\n",
    "        return 'Specific Season'\n",
    "\n",
    "df_nba['Period'] = df_nba['Name - Season'].apply(get_period)\n",
    "print(\"   ‚úÖ Added Period column (Summary Before/After/Specific Season)\")\n",
    "\n",
    "# 7. Extract clean player name\n",
    "def extract_player_name(name_season):\n",
    "    if pd.isnull(name_season):\n",
    "        return np.nan\n",
    "    name_str = str(name_season)\n",
    "    # Remove ' summary before', ' summary after', and season\n",
    "    name_clean = name_str.replace(' summary before', '').replace(' summary after', '')\n",
    "    # Remove season (e.g., ' - 2019/20')\n",
    "    if ' - ' in name_clean:\n",
    "        name_clean = name_clean.split(' - ')[0]\n",
    "    return name_clean.strip()\n",
    "\n",
    "df_nba['Player_Name'] = df_nba['Name - Season'].apply(extract_player_name)\n",
    "print(\"   ‚úÖ Added Player_Name column (clean player name)\")\n",
    "\n",
    "print(f\"\\n‚úÖ NBA processed: {df_nba.shape[0]} rows √ó {df_nba.shape[1]} columns\")\n",
    "print(f\"   New columns: League, Injury_Type, FG_made, FG_attempted, 3PT_made, 3PT_attempted, FT_made, FT_attempted, GS_percent, Period, Player_Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "print(\"üìä Sample rows after processing (NBA):\")\n",
    "display(df_nba[['Player_Name', 'Period', 'League', 'Injury_Type', 'games played', 'PTS', 'FG_made', 'FG_attempted', 'GS_percent']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. WNBA Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚öôÔ∏è WNBA DATA PROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Copy of raw data\n",
    "df_wnba = df_wnba_raw.copy()\n",
    "\n",
    "# 1. Add League column\n",
    "df_wnba['League'] = 'WNBA'\n",
    "\n",
    "# 2. Add Injury_Type column\n",
    "df_wnba['Injury_Type'] = 'ACL'\n",
    "\n",
    "# 3. Gender column standardization (WNBA already has 'Gender')\n",
    "# Already OK\n",
    "\n",
    "# 4. Split made-attempted columns\n",
    "print(\"\\nüìä Splitting Field Goals (FG), 3-Point (3PT), Free Throws (FT) columns...\")\n",
    "\n",
    "# Field Goals\n",
    "if 'Field goals made-attempted per game' in df_wnba.columns:\n",
    "    fg_split = df_wnba['Field goals made-attempted per game'].apply(split_made_attempted)\n",
    "    df_wnba['FG_made'] = fg_split.apply(lambda x: x[0])\n",
    "    df_wnba['FG_attempted'] = fg_split.apply(lambda x: x[1])\n",
    "    print(\"   ‚úÖ FG split into FG_made and FG_attempted\")\n",
    "\n",
    "# 3-Point\n",
    "if 'Three-point field goals made-attempted per game' in df_wnba.columns:\n",
    "    tpt_split = df_wnba['Three-point field goals made-attempted per game'].apply(split_made_attempted)\n",
    "    df_wnba['3PT_made'] = tpt_split.apply(lambda x: x[0])\n",
    "    df_wnba['3PT_attempted'] = tpt_split.apply(lambda x: x[1])\n",
    "    print(\"   ‚úÖ 3PT split into 3PT_made and 3PT_attempted\")\n",
    "\n",
    "# Free Throws\n",
    "if 'Free throws made-attempted per game' in df_wnba.columns:\n",
    "    ft_split = df_wnba['Free throws made-attempted per game'].apply(split_made_attempted)\n",
    "    df_wnba['FT_made'] = ft_split.apply(lambda x: x[0])\n",
    "    df_wnba['FT_attempted'] = ft_split.apply(lambda x: x[1])\n",
    "    print(\"   ‚úÖ FT split into FT_made and FT_attempted\")\n",
    "\n",
    "# 5. Calculate GS_percent\n",
    "df_wnba['GS_percent'] = np.nan\n",
    "mask = (df_wnba['games played'].notna()) & (df_wnba['games played'] > 0)\n",
    "df_wnba.loc[mask, 'GS_percent'] = (df_wnba.loc[mask, 'GS'] / df_wnba.loc[mask, 'games played'] * 100).round(2)\n",
    "print(\"   ‚úÖ Added GS_percent (% of games started)\")\n",
    "\n",
    "# 6. Extract period info\n",
    "df_wnba['Period'] = df_wnba['Name - Season'].apply(get_period)\n",
    "print(\"   ‚úÖ Added Period column\")\n",
    "\n",
    "# 7. Extract clean player name\n",
    "df_wnba['Player_Name'] = df_wnba['Name - Season'].apply(extract_player_name)\n",
    "print(\"   ‚úÖ Added Player_Name column\")\n",
    "\n",
    "print(f\"\\n‚úÖ WNBA processed: {df_wnba.shape[0]} rows √ó {df_wnba.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "print(\"üìä Sample rows after processing (WNBA):\")\n",
    "display(df_wnba[['Player_Name', 'Period', 'League', 'Injury_Type', 'games played', 'PTS', 'FG_made', 'FG_attempted', 'GS_percent']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Soccer Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚öôÔ∏è SOCCER DATA PROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Copy of raw data\n",
    "df_soccer = df_soccer_raw.copy()\n",
    "\n",
    "# 1. Add injury categorization\n",
    "print(\"\\nüìä Categorizing injuries...\")\n",
    "df_soccer['Injury_Category'] = df_soccer['Injury'].apply(categorize_injury)\n",
    "\n",
    "# Check category distribution\n",
    "print(\"\\n   Injury category distribution:\")\n",
    "print(df_soccer['Injury_Category'].value_counts())\n",
    "\n",
    "# 2. Date conversion\n",
    "print(\"\\nüìä Converting injury dates...\")\n",
    "df_soccer['Date of Injury'] = pd.to_datetime(df_soccer['Date of Injury'], errors='coerce')\n",
    "df_soccer['Date of return'] = pd.to_datetime(df_soccer['Date of return'], errors='coerce')\n",
    "\n",
    "# 3. Calculate absence duration (days)\n",
    "df_soccer['Days_Absent'] = (df_soccer['Date of return'] - df_soccer['Date of Injury']).dt.days\n",
    "    print(\"   ‚úÖ Added Days_Absent column (days absent)\")\n",
    "\n",
    "# 4. Add League column for consistency\n",
    "df_soccer['League'] = 'Soccer'\n",
    "\n",
    "print(f\"\\n‚úÖ Soccer processed: {df_soccer.shape[0]} rows √ó {df_soccer.shape[1]} columns\")\n",
    "print(f\"   New columns: Injury_Category, Days_Absent, League\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check absence duration stats\n",
    "print(\"üìä Days absent statistics:\")\n",
    "print(df_soccer['Days_Absent'].describe())\n",
    "\n",
    "print(\"\\nüìä Sample rows after processing (Soccer):\")\n",
    "display(df_soccer[['Name', 'Injury', 'Injury_Category', 'Date of Injury', 'Date of return', 'Days_Absent', 'League']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Collegiate Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚öôÔ∏è COLLEGIATE DATA PROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Copy of raw data\n",
    "df_collegiate = df_collegiate_raw.copy()\n",
    "\n",
    "# 1. Add League column\n",
    "df_collegiate['League'] = 'Collegiate'\n",
    "\n",
    "# 2. Calculate BMI\n",
    "print(\"\\nüìä Calculating BMI...\")\n",
    "df_collegiate['BMI'] = df_collegiate['Weight_kg'] / ((df_collegiate['Height_cm'] / 100) ** 2)\n",
    "df_collegiate['BMI'] = df_collegiate['BMI'].round(2)\n",
    "    print(\"   ‚úÖ Added BMI column\")\n",
    "\n",
    "# 3. ACL risk categorization\n",
    "def categorize_acl_risk(score):\n",
    "    if pd.isnull(score):\n",
    "        return 'Unknown'\n",
    "    if score < 25:\n",
    "        return 'Low'\n",
    "    elif score < 50:\n",
    "        return 'Medium'\n",
    "    elif score < 75:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Very High'\n",
    "\n",
    "df_collegiate['ACL_Risk_Category'] = df_collegiate['ACL_Risk_Score'].apply(categorize_acl_risk)\n",
    "print(\"   ‚úÖ Added ACL_Risk_Category column (Low/Medium/High/Very High)\")\n",
    "\n",
    "# 4. Training Load Score (combination of intensity and hours)\n",
    "df_collegiate['Training_Load_Score'] = (df_collegiate['Training_Intensity'] * \n",
    "                                         df_collegiate['Training_Hours_Per_Week']).round(2)\n",
    "print(\"   ‚úÖ Added Training_Load_Score column\")\n",
    "\n",
    "print(f\"\\n‚úÖ Collegiate processed: {df_collegiate.shape[0]} rows √ó {df_collegiate.shape[1]} columns\")\n",
    "print(f\"   New columns: League, BMI, ACL_Risk_Category, Training_Load_Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä ACL risk category distribution:\")\n",
    "print(df_collegiate['ACL_Risk_Category'].value_counts())\n",
    "\n",
    "print(\"\\nüìä Sample rows after processing (Collegiate):\")\n",
    "display(df_collegiate[['Athlete_ID', 'Gender', 'Position', 'BMI', 'ACL_Risk_Score', 'ACL_Risk_Category', 'Training_Load_Score', 'Injury_Indicator']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Combining NBA and WNBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚öôÔ∏è COMBINING NBA AND WNBA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Make sure columns are in the same order\n",
    "# First find common columns\n",
    "nba_cols = set(df_nba.columns)\n",
    "wnba_cols = set(df_wnba.columns)\n",
    "\n",
    "common_cols = nba_cols.intersection(wnba_cols)\n",
    "nba_only = nba_cols - wnba_cols\n",
    "wnba_only = wnba_cols - nba_cols\n",
    "\n",
    "print(f\"\\nüìä Common columns: {len(common_cols)}\")\n",
    "if nba_only:\n",
    "    print(f\"üìä Only in NBA: {nba_only}\")\n",
    "if wnba_only:\n",
    "    print(f\"üìä Only in WNBA: {wnba_only}\")\n",
    "\n",
    "# Combine datasets\n",
    "df_basketball_combined = pd.concat([df_nba, df_wnba], ignore_index=True, sort=False)\n",
    "\n",
    "print(f\"\\n‚úÖ NBA and WNBA combined:\")\n",
    "print(f\"   NBA: {len(df_nba)} rows\")\n",
    "print(f\"   WNBA: {len(df_wnba)} rows\")\n",
    "print(f\"   Total: {len(df_basketball_combined)} rows\")\n",
    "\n",
    "print(\"\\nüìä League distribution in combined dataset:\")\n",
    "print(df_basketball_combined['League'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Creating Summary Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚öôÔ∏è CREATING SUMMARY SHEETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 13.1 Summary Statistics - Basketball\n",
    "print(\"\\nüìä Creating basketball summary...\")\n",
    "\n",
    "# Only summary before/after rows\n",
    "basketball_summary = df_basketball_combined[\n",
    "    df_basketball_combined['Period'].isin(['Summary Before', 'Summary After'])\n",
    "].copy()\n",
    "\n",
    "# Group by League, Player_Name, Period\n",
    "summary_stats_basketball = basketball_summary.groupby(['League', 'Player_Name', 'Period']).agg({\n",
    "    'games played': 'first',\n",
    "    'GS': 'first',\n",
    "    'GS_percent': 'first',\n",
    "    'Minutes played per match': 'first',\n",
    "    'PTS': 'first',\n",
    "    'AST': 'first',\n",
    "    'REB': 'first',\n",
    "    'FG%': 'first',\n",
    "    '3PT%': 'first',\n",
    "    'FT%': 'first',\n",
    "    'Age during the injury': 'first',\n",
    "    'Recovery period': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"   ‚úÖ Basketball Summary: {len(summary_stats_basketball)} rows\")\n",
    "\n",
    "# 13.2 Summary Statistics - Soccer\n",
    "print(\"\\nüìä Creating soccer summary...\")\n",
    "\n",
    "summary_stats_soccer = df_soccer.groupby(['Injury_Category']).agg({\n",
    "    'Name': 'count',\n",
    "    'Days_Absent': ['mean', 'median', 'min', 'max'],\n",
    "    'Age': ['mean', 'min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "summary_stats_soccer.columns = ['_'.join(col).strip('_') for col in summary_stats_soccer.columns.values]\n",
    "summary_stats_soccer.rename(columns={'Name_count': 'Count'}, inplace=True)\n",
    "\n",
    "print(f\"   ‚úÖ Soccer Summary: {len(summary_stats_soccer)} rows\")\n",
    "\n",
    "# 13.3 Summary Statistics - Collegiate\n",
    "print(\"\\nüìä Creating collegiate summary...\")\n",
    "\n",
    "summary_stats_collegiate = df_collegiate.groupby(['Gender', 'ACL_Risk_Category']).agg({\n",
    "    'Athlete_ID': 'count',\n",
    "    'ACL_Risk_Score': ['mean', 'min', 'max'],\n",
    "    'Injury_Indicator': 'sum',\n",
    "    'Training_Load_Score': 'mean',\n",
    "    'Fatigue_Score': 'mean',\n",
    "    'Performance_Score': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "summary_stats_collegiate.columns = ['_'.join(col).strip('_') for col in summary_stats_collegiate.columns.values]\n",
    "summary_stats_collegiate.rename(columns={'Athlete_ID_count': 'Count', 'Injury_Indicator_sum': 'Injuries'}, inplace=True)\n",
    "\n",
    "print(f\"   ‚úÖ Collegiate Summary: {len(summary_stats_collegiate)} rows\")\n",
    "\n",
    "print(\"\\n‚úÖ All summaries created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check summaries\n",
    "print(\"üìä Basketball Summary - example:\")\n",
    "display(summary_stats_basketball.head(10))\n",
    "\n",
    "print(\"\\nüìä Soccer Summary - example:\")\n",
    "display(summary_stats_soccer)\n",
    "\n",
    "print(\"\\nüìä Collegiate Summary - example:\")\n",
    "display(summary_stats_collegiate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üíæ EXPORT TO EXCEL FILE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_file = '/mnt/user-data/outputs/injury_data_consolidated.xlsx'\n",
    "\n",
    "print(f\"\\nüìÇ Creating file: {output_file}\")\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    \n",
    "    # RAW DATA\n",
    "    print(\"\\nüìù Saving raw data...\")\n",
    "    df_nba_raw.to_excel(writer, sheet_name='NBA_Raw', index=False)\n",
    "    print(\"   ‚úÖ NBA_Raw\")\n",
    "    \n",
    "    df_wnba_raw.to_excel(writer, sheet_name='WNBA_Raw', index=False)\n",
    "    print(\"   ‚úÖ WNBA_Raw\")\n",
    "    \n",
    "    df_soccer_raw.to_excel(writer, sheet_name='Soccer_Raw', index=False)\n",
    "    print(\"   ‚úÖ Soccer_Raw\")\n",
    "    \n",
    "    df_collegiate_raw.to_excel(writer, sheet_name='Collegiate_Raw', index=False)\n",
    "    print(\"   ‚úÖ Collegiate_Raw\")\n",
    "    \n",
    "    # PROCESSED DATA\n",
    "    print(\"\\nüìù Saving processed data...\")\n",
    "    df_nba.to_excel(writer, sheet_name='NBA_Processed', index=False)\n",
    "    print(\"   ‚úÖ NBA_Processed\")\n",
    "    \n",
    "    df_wnba.to_excel(writer, sheet_name='WNBA_Processed', index=False)\n",
    "    print(\"   ‚úÖ WNBA_Processed\")\n",
    "    \n",
    "    df_soccer.to_excel(writer, sheet_name='Soccer_Processed', index=False)\n",
    "    print(\"   ‚úÖ Soccer_Processed\")\n",
    "    \n",
    "    df_collegiate.to_excel(writer, sheet_name='Collegiate_Processed', index=False)\n",
    "    print(\"   ‚úÖ Collegiate_Processed\")\n",
    "    \n",
    "    # COMBINED DATA\n",
    "    print(\"\\nüìù Saving combined data...\")\n",
    "    df_basketball_combined.to_excel(writer, sheet_name='Basketball_Combined', index=False)\n",
    "    print(\"   ‚úÖ Basketball_Combined (NBA + WNBA)\")\n",
    "    \n",
    "    # SUMMARIES\n",
    "    print(\"\\nüìù Saving summaries...\")\n",
    "    summary_stats_basketball.to_excel(writer, sheet_name='Summary_Basketball', index=False)\n",
    "    print(\"   ‚úÖ Summary_Basketball\")\n",
    "    \n",
    "    summary_stats_soccer.to_excel(writer, sheet_name='Summary_Soccer', index=False)\n",
    "    print(\"   ‚úÖ Summary_Soccer\")\n",
    "    \n",
    "    summary_stats_collegiate.to_excel(writer, sheet_name='Summary_Collegiate', index=False)\n",
    "    print(\"   ‚úÖ Summary_Collegiate\")\n",
    "\n",
    "print(f\"\\n‚úÖ File saved: {output_file}\")\n",
    "\n",
    "print(f\"\\nüìä File structure:\")\n",
    "    print(f\"   ‚Ä¢ 4 RAW sheets\")\n",
    "    print(f\"   ‚Ä¢ 4 PROCESSED sheets\")\n",
    "    print(f\"   ‚Ä¢ 1 COMBINED sheet (NBA+WNBA)\")\n",
    "    print(f\"   ‚Ä¢ 3 SUMMARY sheets\")\n",
    "    print(f\"   TOTAL: 12 sheets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 15. Validation and Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ DATA VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Check row counts\n",
    "print(\"\\nüìä ROW COUNTS:\")\n",
    "print(f\"   NBA Raw:        {len(df_nba_raw):>6}\")\n",
    "print(f\"   NBA Processed:  {len(df_nba):>6}\")\n",
    "print(f\"   WNBA Raw:       {len(df_wnba_raw):>6}\")\n",
    "print(f\"   WNBA Processed: {len(df_wnba):>6}\")\n",
    "print(f\"   Basketball Combined: {len(df_basketball_combined):>6}\")\n",
    "print(f\"   Soccer Raw:     {len(df_soccer_raw):>6}\")\n",
    "print(f\"   Soccer Processed: {len(df_soccer):>6}\")\n",
    "print(f\"   Collegiate Raw: {len(df_collegiate_raw):>6}\")\n",
    "print(f\"   Collegiate Processed: {len(df_collegiate):>6}\")\n",
    "\n",
    "# 2. Check unique players\n",
    "print(\"\\nüìä UNIQUE PLAYERS:\")\n",
    "nba_players = df_nba[df_nba['Period'] == 'Summary Before']['Player_Name'].nunique()\n",
    "wnba_players = df_wnba[df_wnba['Period'] == 'Summary Before']['Player_Name'].nunique()\n",
    "print(f\"   NBA:   {nba_players:>3} players\")\n",
    "print(f\"   WNBA:  {wnba_players:>3} players\")\n",
    "print(f\"   Soccer: {df_soccer['Name'].nunique():>3} players\")\n",
    "print(f\"   Collegiate: {df_collegiate['Athlete_ID'].nunique():>3} student-athletes\")\n",
    "\n",
    "# 3. Check injury types\n",
    "print(\"\\nüìä INJURY TYPES:\")\n",
    "print(f\"   Basketball: 100% ACL (by design)\")\n",
    "print(f\"   Soccer: {df_soccer['Injury_Category'].nunique()} categories\")\n",
    "print(\"\\n   Top 5 Soccer categories:\")\n",
    "print(df_soccer['Injury_Category'].value_counts().head())\n",
    "\n",
    "# 4. Missing values in key columns\n",
    "print(\"\\nüìä MISSING VALUES (key columns):\")\n",
    "print(\"\\n   NBA:\")\n",
    "key_cols_nba = ['Player_Name', 'Period', 'games played', 'PTS', 'FG_made', 'FG_attempted']\n",
    "for col in key_cols_nba:\n",
    "    if col in df_nba.columns:\n",
    "        missing = df_nba[col].isnull().sum()\n",
    "        pct = (missing / len(df_nba)) * 100\n",
    "        print(f\"      {col:20s}: {missing:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n   WNBA:\")\n",
    "for col in key_cols_nba:\n",
    "    if col in df_wnba.columns:\n",
    "        missing = df_wnba[col].isnull().sum()\n",
    "        pct = (missing / len(df_wnba)) * 100\n",
    "        print(f\"      {col:20s}: {missing:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n   Soccer:\")\n",
    "key_cols_soccer = ['Name', 'Injury', 'Injury_Category', 'Days_Absent']\n",
    "for col in key_cols_soccer:\n",
    "    if col in df_soccer.columns:\n",
    "        missing = df_soccer[col].isnull().sum()\n",
    "        pct = (missing / len(df_soccer)) * 100\n",
    "        print(f\"      {col:20s}: {missing:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n   Collegiate:\")\n",
    "    print(f\"      NO missing values! ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 16. Documentation - Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìñ DATA DICTIONARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "data_dict = {\n",
    "    'Sheet': [],\n",
    "    'Column': [],\n",
    "    'Description': [],\n",
    "    'Type': []\n",
    "}\n",
    "\n",
    "# NBA/WNBA Processed\n",
    "basketball_columns = [\n",
    "    ('Player_Name', 'Player name (clean, without season)', 'Text'),\n",
    "    ('Name - Season', 'Original name with season or summary label', 'Text'),\n",
    "    ('Period', 'Period: Summary Before / Summary After / Specific Season', 'Category'),\n",
    "    ('League', 'League: NBA / WNBA', 'Category'),\n",
    "    ('Injury_Type', 'Injury type (always ACL for basketball)', 'Category'),\n",
    "    ('Gender', 'Gender: Male / Female', 'Category'),\n",
    "    ('games played', 'Number of games played', 'Number'),\n",
    "    ('GS', 'Games Started', 'Number'),\n",
    "    ('GS_percent', 'Percentage of games started', 'Number'),\n",
    "    ('Minutes played per match', 'Average minutes per game', 'Number'),\n",
    "    ('PTS', 'Points per game', 'Number'),\n",
    "    ('AST', 'Assists per game', 'Number'),\n",
    "    ('REB', 'Rebounds per game', 'Number'),\n",
    "    ('FG_made', 'Field goals made per game', 'Number'),\n",
    "    ('FG_attempted', 'Field goal attempts per game', 'Number'),\n",
    "    ('FG%', 'Field goal percentage (%)', 'Number'),\n",
    "    ('3PT_made', 'Three-pointers made per game', 'Number'),\n",
    "    ('3PT_attempted', 'Three-point attempts per game', 'Number'),\n",
    "    ('3PT%', 'Three-point percentage (%)', 'Number'),\n",
    "    ('FT_made', 'Free throws made per game', 'Number'),\n",
    "    ('FT_attempted', 'Free throw attempts per game', 'Number'),\n",
    "    ('FT%', 'Free throw percentage (%)', 'Number'),\n",
    "    ('Age during the injury', 'Age at time of injury', 'Number'),\n",
    "    ('Recovery period', 'Recovery duration (e.g., \"18 months\")', 'Text'),\n",
    "]\n",
    "\n",
    "for col, desc, typ in basketball_columns:\n",
    "    data_dict['Sheet'].append('NBA/WNBA_Processed')\n",
    "    data_dict['Column'].append(col)\n",
    "    data_dict['Description'].append(desc)\n",
    "    data_dict['Type'].append(typ)\n",
    "\n",
    "# Soccer Processed\n",
    "soccer_columns = [\n",
    "    ('Name', 'Player name', 'Text'),\n",
    "    ('Team Name', 'Team name', 'Text'),\n",
    "    ('Position', 'Position on the field', 'Category'),\n",
    "    ('Age', 'Age', 'Number'),\n",
    "    ('Season', 'Season', 'Text'),\n",
    "    ('Injury', 'Original injury name', 'Text'),\n",
    "    ('Injury_Category', 'Injury category (e.g., Knee, Hamstring)', 'Category'),\n",
    "    ('Date of Injury', 'Date of injury', 'Date'),\n",
    "    ('Date of return', 'Date of return', 'Date'),\n",
    "    ('Days_Absent', 'Number of days absent', 'Number'),\n",
    "    ('League', 'League (Soccer)', 'Category'),\n",
    "]\n",
    "\n",
    "for col, desc, typ in soccer_columns:\n",
    "    data_dict['Sheet'].append('Soccer_Processed')\n",
    "    data_dict['Column'].append(col)\n",
    "    data_dict['Description'].append(desc)\n",
    "    data_dict['Type'].append(typ)\n",
    "\n",
    "# Collegiate Processed\n",
    "collegiate_columns = [\n",
    "    ('Athlete_ID', 'Athlete ID', 'Text'),\n",
    "    ('Age', 'Age', 'Number'),\n",
    "    ('Gender', 'Gender: Male / Female', 'Category'),\n",
    "    ('Height_cm', 'Height in cm', 'Number'),\n",
    "    ('Weight_kg', 'Weight in kg', 'Number'),\n",
    "    ('BMI', 'Body Mass Index (calculated)', 'Number'),\n",
    "    ('Position', 'Position: Guard / Forward / Center', 'Category'),\n",
    "    ('Training_Intensity', 'Training intensity', 'Number'),\n",
    "    ('Training_Hours_Per_Week', 'Training hours per week', 'Number'),\n",
    "    ('Training_Load_Score', 'Training load score (calculated)', 'Number'),\n",
    "    ('ACL_Risk_Score', 'ACL risk score (0-100)', 'Number'),\n",
    "    ('ACL_Risk_Category', 'Risk category: Low/Medium/High/Very High', 'Category'),\n",
    "    ('Injury_Indicator', 'Whether injury occurred: 0=No, 1=Yes', 'Binary'),\n",
    "    ('League', 'League (Collegiate)', 'Category'),\n",
    "]\n",
    "\n",
    "for col, desc, typ in collegiate_columns:\n",
    "    data_dict['Sheet'].append('Collegiate_Processed')\n",
    "    data_dict['Column'].append(col)\n",
    "    data_dict['Description'].append(desc)\n",
    "    data_dict['Type'].append(typ)\n",
    "\n",
    "df_data_dict = pd.DataFrame(data_dict)\n",
    "\n",
    "print(\"\\nüìñ Data dictionary created\")\n",
    "print(f\"   Number of described columns: {len(df_data_dict)}\")\n",
    "\n",
    "display(df_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data dictionary to a separate file\n",
    "data_dict_file = '/mnt/user-data/outputs/data_dictionary.xlsx'\n",
    "df_data_dict.to_excel(data_dict_file, index=False)\n",
    "print(f\"‚úÖ Data Dictionary saved: {data_dict_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 17. Project Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ DATA PROCESSING PROJECT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "‚úÖ DATA PROCESSING COMPLETED\n",
    "\n",
    "üìÅ OUTPUT FILES:\n",
    "   1. injury_data_consolidated.xlsx - main data file (12 sheets)\n",
    "   2. data_dictionary.xlsx - data dictionary\n",
    "\n",
    "üìä DATA STRUCTURE:\n",
    "   \n",
    "   RAW:\n",
    "   ‚Ä¢ NBA_Raw - 120 rows\n",
    "   ‚Ä¢ WNBA_Raw - 60 rows\n",
    "   ‚Ä¢ Soccer_Raw - 656 rows\n",
    "   ‚Ä¢ Collegiate_Raw - 200 rows\n",
    "   \n",
    "   PROCESSED:\n",
    "   ‚Ä¢ NBA_Processed - split FG/3PT/FT columns, added GS_percent, Period, Player_Name\n",
    "   ‚Ä¢ WNBA_Processed - same as above\n",
    "   ‚Ä¢ Soccer_Processed - injury categorization, calculated Days_Absent\n",
    "   ‚Ä¢ Collegiate_Processed - BMI, ACL_Risk_Category, Training_Load_Score\n",
    "   \n",
    "   COMBINED:\n",
    "   ‚Ä¢ Basketball_Combined - NBA + WNBA together (180 rows)\n",
    "   \n",
    "   SUMMARIES:\n",
    "   ‚Ä¢ Summary_Basketball - before/after stats for each player\n",
    "   ‚Ä¢ Summary_Soccer - stats per injury category\n",
    "   ‚Ä¢ Summary_Collegiate - stats per gender and ACL risk category\n",
    "\n",
    "üîë KEY TRANSFORMATIONS:\n",
    "   ‚úì Split \"made-attempted\" columns (FG, 3PT, FT)\n",
    "   ‚úì Added League, Injury_Type, Period columns\n",
    "   ‚úì Soccer injury categorization (14 categories)\n",
    "   ‚úì Calculated metrics: GS_percent, Days_Absent, BMI, Training_Load_Score\n",
    "   ‚úì Extracted clean player names (Player_Name)\n",
    "   ‚úì Standardized dates in Soccer\n",
    "\n",
    "üìà NEXT STEPS:\n",
    "   1. Exploratory Data Analysis (EDA)\n",
    "   2. Comparative visualizations\n",
    "   3. PCA Analysis\n",
    "   4. Radar charts\n",
    "   5. Clustering / Modeling\n",
    "\n",
    "üí° NOTES:\n",
    "   ‚Ä¢ Data is ready for analysis\n",
    "   ‚Ä¢ All missing values are marked (NaN)\n",
    "   ‚Ä¢ Filter by: League, Injury_Type, Injury_Category, Period\n",
    "   ‚Ä¢ Compare: NBA vs WNBA, different Soccer injuries, Collegiate risk categories\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"üìÖ Processing completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}